import os
import sys
from pathlib import Path
from typing import List

import streamlit as st
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

# Ensure project root is on sys.path when running via `streamlit run`
PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from career_matcher import profile_builder
from career_matcher.rag_retriever import build_reranked_retriever


st.set_page_config(page_title="ì»¤ë¦¬ì–´ ë§¤ì¹­ RAG", page_icon="ğŸ§­", layout="wide")


@st.cache_resource(show_spinner="LLM ë¡œë”© ì¤‘...")
def load_llm():
    # TODO: ì‹¤ì œ í‚¤ë¥¼ ë„£ì§€ ë§ê³  í™˜ê²½ ë³€ìˆ˜/Secret Managerë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    # os.environ.setdefault("OPENAI_API_KEY", "YOUR_API_KEY_HERE")
    return ChatOpenAI(model="gpt-5-mini", temperature=1.0)


@st.cache_resource(show_spinner="ë²¡í„° DB + Reranker ì¤€ë¹„ ì¤‘...")
def load_retriever():
    return build_reranked_retriever()


def summarize_profile(parsed_profile: profile_builder.UserProfile) -> str:
    lines = [
        f"- ì§ë¬´ í›„ë³´: {', '.join(parsed_profile.job_terms) or 'ë¯¸ì •'}",
        f"- ìŠ¤í‚¬: {', '.join(parsed_profile.skill_terms) or 'ë¯¸ì •'}",
        f"- ìœ„ì¹˜: {', '.join(parsed_profile.location_terms) or 'ë¬´ê´€'}",
    ]
    if parsed_profile.experience_years is not None:
        lines.append(f"- ê²½ë ¥: {parsed_profile.experience_years}ë…„ì°¨")
    elif parsed_profile.seniority_label:
        lines.append(f"- ê²½ë ¥ ë ˆë²¨: {parsed_profile.seniority_label}")
    lines.append(f"- ì¶”ì²œ í‚¤ì›Œë“œ: {', '.join(parsed_profile.suggested_keywords)}")
    return "\n".join(lines)


def build_prompt(mode: str = "recommend"):
    if mode == "resume":
        template = """
ë‹¹ì‹ ì€ ì»¤ë¦¬ì–´ ì½”ì¹˜ ê²¸ ì´ë ¥ì„œ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì•„ë˜ ì •ë³´ë¥¼ í† ëŒ€ë¡œ íŠ¹ì • í¬ì§€ì…˜ì— ë§ì¶˜ í•µì‹¬ ë¬¸ì¥(ì´ë ¥ì„œ bullet ë˜ëŠ” ìê¸°ì†Œê°œì„œ ìš”ì•½)ì„ ì‘ì„±í•˜ì„¸ìš”.

[ì‚¬ìš©ì í”„ë¡œí•„]
{profile}

[ëŒ€í™” ê¸°ë¡]
{history}

[ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸]
{context}

ì§€ì¹¨:
- STAR(ìƒí™©-ê³¼ì œ-í–‰ë™-ì„±ê³¼) êµ¬ì¡°ë¥¼ ê°„ë‹¨íˆ ë°˜ì˜í•œ 2~3ë¬¸ì¥ì„ í•œ ë¸”ë¡ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”.
- ì •ëŸ‰ ì§€í‘œ(%, ë°°, ì‹œê°„ ë‹¨ì¶• ë“±)ê°€ ìˆìœ¼ë©´ ë°˜ì˜í•˜ê³ , ì—†ìœ¼ë©´ í•©ë¦¬ì  ì¶”ì •ì¹˜ë¥¼ ì œì•ˆí•˜ì‹­ì‹œì˜¤.
- ë§ˆì§€ë§‰ ì¤„ì— "ë‹¤ìŒ ì œì•ˆ" í˜•íƒœë¡œ ì¶”ê°€ ì‚¬ê³  ë°©í–¥(ì˜ˆ: ê°•ì¡°í•  ì—­ëŸ‰, ë³´ì™„í•  ë°ì´í„°)ì„ 1ì¤„ ì œì‹œí•˜ì‹­ì‹œì˜¤.

[ì‚¬ìš©ì ìš”ì²­]
{question}
"""
    else:
        template = """
ë‹¹ì‹ ì€ ì»¤ë¦¬ì–´ ë§¤ì¹­ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì•„ë˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

[ì‚¬ìš©ì í”„ë¡œí•„]
{profile}

[ëŒ€í™” ê¸°ë¡]
{history}

[ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸]
{context}

ì§€ì¹¨:
- ìµœëŒ€ 3ê°œì˜ ì¶”ì²œ í¬ì§€ì…˜ì„ ì¹´ë“œ í˜•íƒœë¡œ ì œì‹œí•˜ì‹­ì‹œì˜¤.
- ê° í¬ì§€ì…˜ë§ˆë‹¤ 'ì´ìœ /ê°•ì 'ì„ í•œ ì¤„ë¡œ ìš”ì•½í•˜ê³ , í•„ìš” ì‹œ ìš”êµ¬ ìŠ¤í‚¬/ê·¼ë¬´ì§€/ê²½ë ¥ ì¡°ê±´ì„ ì–¸ê¸‰í•˜ì‹­ì‹œì˜¤.
- ì‚¬ìš©ìê°€ ì¶”ê°€ ì§ˆë¬¸ì„ í•˜ë„ë¡ ë‹¤ìŒ í–‰ë™ì„ ì œì•ˆí•˜ì‹­ì‹œì˜¤.

[ì‚¬ìš©ì ì§ˆë¬¸]
{question}
"""
    return ChatPromptTemplate.from_template(template)


def run_rag(question: str, history: List[str], profile_text: str, mode: str = "recommend"):
    retriever = load_retriever()
    docs = retriever.get_relevant_documents(question)
    context = "\n\n".join(doc.page_content for doc in docs)
    prompt = build_prompt(mode=mode)
    chain = prompt | load_llm()
    response = chain.invoke(
        {
            "profile": profile_text,
            "history": "\n".join(history[-5:]),
            "context": context,
            "question": question,
        }
    )
    return response.content, docs


def init_session():
    st.session_state.setdefault("profile", None)
    st.session_state.setdefault("profile_summary", "")
    st.session_state.setdefault("chat_history", [])
    st.session_state.setdefault("conversation", [])
    st.session_state.setdefault("recommended_cards", [])


def main():
    init_session()
    st.title("ğŸ§­ ì»¤ë¦¬ì–´ ë§¤ì¹­ RAG ì±—ë´‡")
    st.caption("dragonkue ì„ë² ë”© + BGE Reranker + ChatGPT ê¸°ë°˜ ë§ì¶¤í˜• ê³µê³  ì¶”ì²œ")

    with st.sidebar:
        st.header("1. í”„ë¡œí•„ ì…ë ¥")
        profile_text = st.text_area("ì§ë¬´/ìŠ¤í‚¬/ìê¸°ì†Œê°œë¥¼ ììœ ë¡­ê²Œ ì¨ì£¼ì„¸ìš”", height=120)
        if st.button("í”„ë¡œí•„ ë¶„ì„"):
            if not profile_text.strip():
                st.warning("í”„ë¡œí•„ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                parsed = profile_builder.build_profile(profile_text)
                summary = summarize_profile(parsed)
                st.session_state.profile = parsed
                st.session_state.profile_summary = summary
                st.success("í”„ë¡œí•„ ë¶„ì„ ì™„ë£Œ!")
        if st.session_state.profile_summary:
            st.markdown("### í˜„ì¬ í”„ë¡œí•„ ìš”ì•½")
            st.markdown(st.session_state.profile_summary)
            st.markdown("---")
        st.write("**Tip**: `vector_pipeline.py`ì™€ `rag_retriever.py`ë¥¼ ë¯¸ë¦¬ ì‹¤í–‰í•´ì•¼ ê²€ìƒ‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

    st.subheader("2. ì»¤ë¦¬ì–´ ìƒë‹´")
    if not st.session_state.profile:
        st.info("ì™¼ìª½ì—ì„œ í”„ë¡œí•„ì„ ë¨¼ì € ë“±ë¡í•˜ì„¸ìš”.")
        return

    mode = st.radio(
        "ìƒë‹´ ëª¨ë“œ ì„ íƒ",
        options=["ì¶”ì²œ ë°›ê¸°", "ì´ë ¥ì„œ/ìì†Œì„œ ë¬¸ì¥ ìƒì„±"],
        horizontal=True,
    )

    extra_input = ""
    project_input = ""
    if mode == "ì´ë ¥ì„œ/ìì†Œì„œ ë¬¸ì¥ ìƒì„±":
        if st.session_state.recommended_cards:
            card = st.session_state.get("selected_card")
            default_title = card["title"] if card else ""
            st.info("ì¶”ì²œ ì¹´ë“œ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ë©´ í•´ë‹¹ í¬ì§€ì…˜ëª…ì´ ìë™ìœ¼ë¡œ ì…ë ¥ë©ë‹ˆë‹¤.")
            extra_input = st.text_input(
                "íƒ€ê¹ƒ í¬ì§€ì…˜ / íšŒì‚¬ëª…",
                value=default_title,
                placeholder="ì˜ˆ: í† ìŠ¤ì¦ê¶Œ ML Engineer",
            )
        else:
            extra_input = st.text_input("íƒ€ê¹ƒ í¬ì§€ì…˜ / íšŒì‚¬ëª…ì„ ì ì–´ì£¼ì„¸ìš”", placeholder="ì˜ˆ: í† ìŠ¤ì¦ê¶Œ ML Engineer")
        project_input = st.text_area("ê°•ì¡°í•  í”„ë¡œì íŠ¸/ì„±ê³¼ (ì„ íƒ ì‚¬í•­)", height=100)

    chat_container = st.container()
    query = st.text_input(
        "ì§ˆë¬¸ ë˜ëŠ” ìš”ì²­ì„ ì…ë ¥í•˜ì„¸ìš”",
        placeholder="ì˜ˆ: â€œLLM ê²½í—˜ ì‚´ë¦´ ìˆ˜ ìˆëŠ” í¬ì§€ì…˜ ì¶”ì²œí•´ì¤˜â€",
    )
    if st.button("ì¶”ì²œ ë°›ê¸°", use_container_width=True):
        if not query.strip():
            st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            mode_key = "resume" if mode == "ì´ë ¥ì„œ/ìì†Œì„œ ë¬¸ì¥ ìƒì„±" else "recommend"
            user_query = query
            if mode_key == "resume":
                user_query = f"íƒ€ê¹ƒ í¬ì§€ì…˜: {extra_input or 'ë¯¸ì •'}\ní”„ë¡œì íŠ¸/ì„±ê³¼: {project_input or 'ì‚¬ìš©ì ë¯¸ì…ë ¥'}\nìš”ì²­: {query}"
            with st.spinner("ì¶”ì²œì„ ìƒì„± ì¤‘..."):
                response, docs = run_rag(
                    user_query,
                    st.session_state.chat_history,
                    st.session_state.profile_summary,
                    mode=mode_key,
                )
                st.session_state.conversation.append(("user", user_query))
                st.session_state.conversation.append(("assistant", response))
                st.session_state.chat_history.append(f"ì‚¬ìš©ì: {user_query}")
                st.session_state.chat_history.append(f"AI: {response}")
                st.session_state["last_docs"] = docs
                if mode_key == "recommend":
                    st.session_state.recommended_cards = [
                        {
                            "title": doc.metadata.get("title", "ì œëª© ì—†ìŒ"),
                            "job_id": doc.metadata.get("job_id", ""),
                            "snippet": doc.page_content.splitlines()[0:6],
                        }
                        for doc in docs
                    ]

    with chat_container:
        for role, text in st.session_state.conversation[-10:]:
            with st.chat_message(role):
                st.markdown(text)

    if st.session_state.recommended_cards:
        st.subheader("ì¶”ì²œ ì¹´ë“œ")
        selected_card = st.radio(
            "ì´ë ¥ì„œ/ìì†Œì„œ ë¬¸ì¥ì„ ìƒì„±í•  í¬ì§€ì…˜ì„ ì„ íƒí•˜ì„¸ìš”",
            options=range(len(st.session_state.recommended_cards)),
            format_func=lambda idx: st.session_state.recommended_cards[idx]["title"],
            key="selected_card_idx",
        )
        st.session_state["selected_card"] = st.session_state.recommended_cards[selected_card]


if __name__ == "__main__":
    if not os.path.exists("career_matcher/vector_db"):
        st.warning("vector_dbê°€ ì—†ìŠµë‹ˆë‹¤. `python career_matcher/vector_pipeline.py --limit 1000`ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    main()
