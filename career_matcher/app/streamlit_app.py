import sqlite3
from datetime import datetime, date
from pathlib import Path
from typing import Any, Dict, List, Optional

import streamlit as st

from career_matcher.configs import settings
from career_matcher.processing import keyword_parser
from career_matcher.retriever import rag_retriever
from career_matcher.retriever.rag_retriever import RerankedJobRetriever, _compute_skill_weight, _compute_recency_weight, _normalize_distance
from career_matcher.retriever.reranker import rerank_documents


st.set_page_config(page_title="ì»¤ë¦¬ì–´ ë§¤ì¹­ ì¶”ì²œ", page_icon="ğŸ§­", layout="wide")


# ------------------------------------------------------------
# Helpers: DB lookup & metadata enrichment
# ------------------------------------------------------------


def load_job_details(job_id: str) -> Dict[str, Any]:
    """
    SQLiteì—ì„œ job_idë¡œ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•´ ë©”íƒ€ë°ì´í„°ë¥¼ ë³´ê°•í•œë‹¤.
    """
    if not job_id:
        return {}
    conn = sqlite3.connect(settings.SQLITE_PATH)
    row = conn.execute(
        """
        SELECT job_id, title, company, location, career, education, job_category,
               skills, summary, url, posted_at, due_date
        FROM job_postings WHERE job_id = ?
        """,
        (job_id,),
    ).fetchone()
    conn.close()
    if not row:
        return {}
    keys = [
        "job_id",
        "title",
        "company",
        "location",
        "career",
        "education",
        "job_category",
        "skills",
        "summary",
        "url",
        "posted_at",
        "due_date",
    ]
    return dict(zip(keys, row))


def enrich_doc_metadata(doc):
    meta = doc.metadata or {}
    job_id = meta.get("id") or meta.get("job_id")
    if job_id:
        extra = load_job_details(job_id)
        merged = {**meta, **extra}
        merged.setdefault("job_id", job_id)
        doc.metadata = merged
    return doc


# ------------------------------------------------------------
# Retriever wrapper with scoring breakdown
# ------------------------------------------------------------


def rank_with_breakdown(
    query: str,
    fetch_k: int,
    top_n: int,
    min_skill: float,
    max_age_days: int,
) -> List[Dict[str, Any]]:
    """
    retriever v2ë¥¼ í™œìš©í•´ ìŠ¤ì½”ì–´ ë¸Œë ˆì´í¬ë‹¤ìš´ê³¼ í•¨ê»˜ ê²°ê³¼ ë°˜í™˜.
    """
    retriever = RerankedJobRetriever(fetch_k=fetch_k, top_n=top_n)

    raw = retriever._search_with_scores(query)  # type: ignore[attr-defined]
    if not raw:
        return []

    scored = []
    for doc, distance in raw:
        doc = enrich_doc_metadata(doc)
        semantic = _normalize_distance(distance)
        recency = _compute_recency_weight((doc.metadata or {}).get("posted_at") if isinstance(doc.metadata, dict) else None)
        skill = _compute_skill_weight(query, doc)
        combined = semantic * 0.7 + recency * 0.2 + skill * 0.1

        # recency í•„í„°
        if max_age_days is not None and max_age_days > 0:
            posted = (doc.metadata or {}).get("posted_at")
            try:
                d_posted = datetime.strptime(str(posted)[:10], "%Y-%m-%d").date()
                days_old = (date.today() - d_posted).days
                if days_old > max_age_days:
                    continue
            except Exception:
                pass

        # skill í•„í„°
        if skill < min_skill:
            continue

        scored.append(
            {
                "doc": doc,
                "semantic": semantic,
                "recency": recency,
                "skill": skill,
                "combined": combined,
                "distance": distance,
            }
        )

    # 1ì°¨ ì •ë ¬
    scored.sort(key=lambda x: x["combined"], reverse=True)
    candidate_docs = [s["doc"] for s in scored]

    # reranker ì¬ì •ë ¬
    reranked_docs = rerank_documents(candidate_docs, query, top_n=top_n)

    # rerank ê²°ê³¼ì— ìŠ¤ì½”ì–´ ë§¤í•‘
    index_by_id = {}
    for s in scored:
        meta = s["doc"].metadata or {}
        key = meta.get("job_id") or meta.get("id") or s["doc"].page_content[:50]
        index_by_id[key] = s

    results = []
    for doc in reranked_docs:
        meta = doc.metadata or {}
        key = meta.get("job_id") or meta.get("id") or doc.page_content[:50]
        base = index_by_id.get(key, {})
        results.append(
            {
                "doc": doc,
                "meta": meta,
                "semantic": base.get("semantic"),
                "recency": base.get("recency"),
                "skill": base.get("skill"),
                "combined": base.get("combined"),
            }
        )
    return results[:top_n]


# ------------------------------------------------------------
# UI helpers
# ------------------------------------------------------------


def render_score_bar(label: str, value: Optional[float], help_text: str = ""):
    col1, col2 = st.columns([1, 3])
    with col1:
        st.caption(label)
    with col2:
        pct = 0.0 if value is None else max(0.0, min(1.0, value)) * 100
        st.progress(pct / 100.0, text=f"{pct:.0f}% {help_text}")


def render_job_card(item: Dict[str, Any]):
    doc = item["doc"]
    meta = item.get("meta", {}) or {}
    title = meta.get("title") or "ì œëª© ì—†ìŒ"
    company = meta.get("company") or "íšŒì‚¬ ì •ë³´ ì—†ìŒ"
    location = meta.get("location") or "ì§€ì—­ ì •ë³´ ì—†ìŒ"
    url = meta.get("url")
    skills = meta.get("skills", "")
    summary = meta.get("summary") or doc.page_content.splitlines()[1:3]
    combined = item.get("combined")
    recency = item.get("recency")
    skill = item.get("skill")
    semantic = item.get("semantic")

    with st.container(border=True):
        st.markdown(f"### {title}")
        st.markdown(f"**{company}** Â· {location}")
        cols = st.columns(4)
        cols[0].metric("Combined", f"{(combined or 0)*100:.0f}")
        cols[1].metric("Semantic", f"{(semantic or 0)*100:.0f}")
        cols[2].metric("Recency", f"{(recency or 0)*100:.0f}")
        cols[3].metric("Skill", f"{(skill or 0)*100:.0f}")

        if summary:
            st.write("**ìš”ì•½**")
            if isinstance(summary, list):
                st.markdown("<br>".join(summary), unsafe_allow_html=True)
            else:
                st.write(summary)

        if skills:
            st.write(f"**ìš”êµ¬ ìŠ¤í‚¬**: {skills}")
        if url:
            st.link_button("ê³µê³  ë³´ê¸°", url, use_container_width=True)


def profile_block():
    st.subheader("í”„ë¡œí•„ ì…ë ¥")
    profile_text = st.text_area("ì§ë¬´/ìŠ¤í‚¬/ìê¸°ì†Œê°œë¥¼ ììœ ë¡­ê²Œ ì¨ì£¼ì„¸ìš”", height=140, key="profile_input")
    if st.button("í”„ë¡œí•„ ë¶„ì„"):
        if not profile_text.strip():
            st.warning("í”„ë¡œí•„ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            parsed = keyword_parser.build_profile(profile_text)
            summary = summarize_profile(parsed)
            st.session_state.profile = parsed
            st.session_state.profile_summary = summary
            st.session_state.suggested_query = " ".join(parsed.suggested_keywords) or profile_text
            st.success("í”„ë¡œí•„ ë¶„ì„ ì™„ë£Œ!")
    if st.session_state.profile_summary:
        st.markdown("### í˜„ì¬ í”„ë¡œí•„ ìš”ì•½")
        st.markdown(st.session_state.profile_summary)
        st.info(f"ì¶”ì²œ ê²€ìƒ‰ì–´: {st.session_state.get('suggested_query', '')}")


def summarize_profile(parsed_profile: keyword_parser.UserProfile) -> str:
    lines = [
        f"- ì§ë¬´ í›„ë³´: {', '.join(parsed_profile.job_terms) or 'ë¯¸ì •'}",
        f"- ìŠ¤í‚¬: {', '.join(parsed_profile.skill_terms) or 'ë¯¸ì •'}",
        f"- ìœ„ì¹˜: {', '.join(parsed_profile.location_terms) or 'ë¬´ê´€'}",
    ]
    if parsed_profile.experience_years is not None:
        lines.append(f"- ê²½ë ¥: {parsed_profile.experience_years}ë…„ì°¨")
    elif parsed_profile.seniority_label:
        lines.append(f"- ê²½ë ¥ ë ˆë²¨: {parsed_profile.seniority_label}")
    lines.append(f"- ì¶”ì²œ í‚¤ì›Œë“œ: {', '.join(parsed_profile.suggested_keywords)}")
    return "\n".join(lines)


def ensure_session():
    st.session_state.setdefault("profile", None)
    st.session_state.setdefault("profile_summary", "")
    st.session_state.setdefault("suggested_query", "")
    st.session_state.setdefault("results", [])


# ------------------------------------------------------------
# Main UI
# ------------------------------------------------------------


def tab_recommend():
    st.header("ì¶”ì²œ ê²°ê³¼")
    col_filters = st.columns(4)
    with col_filters[0]:
        fetch_k = st.number_input("ì´ˆê¸° ê²€ìƒ‰ ê°œìˆ˜ (fetch_k)", min_value=5, max_value=100, value=30, step=5)
    with col_filters[1]:
        top_n = st.number_input("ìµœì¢… ì¶”ì²œ ê°œìˆ˜ (top_n)", min_value=1, max_value=20, value=5, step=1)
    with col_filters[2]:
        min_skill = st.slider("ìµœì†Œ ìŠ¤í‚¬ ë§¤ì¹­", min_value=0, max_value=100, value=30, step=5) / 100.0
    with col_filters[3]:
        max_age_days = st.slider("ìµœê·¼ Nì¼ ê³µê³ ë§Œ", min_value=0, max_value=180, value=90, step=15)

    default_query = st.session_state.get("suggested_query", "")
    query = st.text_input("ê²€ìƒ‰ ì¿¼ë¦¬", value=default_query, placeholder="ì˜ˆ: LLM ë°ì´í„° ì—”ì§€ë‹ˆì–´ í¬ì§€ì…˜ ì¶”ì²œ")

    if st.button("ì¶”ì²œ ì‹¤í–‰", use_container_width=True):
        if not query.strip():
            st.warning("ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            with st.spinner("ì¶”ì²œ ì¤‘..."):
                results = rank_with_breakdown(
                    query=query,
                    fetch_k=int(fetch_k),
                    top_n=int(top_n),
                    min_skill=min_skill,
                    max_age_days=int(max_age_days),
                )
                st.session_state.results = results

    if not st.session_state.results:
        st.info("ì¶”ì²œ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")
        return

    for item in st.session_state.results:
        render_job_card(item)


def tab_skills():
    st.header("ìŠ¤í‚¬ ë§¤ì¹­ ë¶„ì„")
    if not st.session_state.results:
        st.info("ì¶”ì²œì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    for idx, item in enumerate(st.session_state.results, start=1):
        meta = item.get("meta", {}) or {}
        st.markdown(f"### Top {idx}: {meta.get('title', 'ì œëª© ì—†ìŒ')}")
        user_skills = set(st.session_state.profile.skill_terms) if st.session_state.profile else set()
        job_skills = set(rag_retriever._extract_skill_tokens(meta.get("skills", "")))  # type: ignore[attr-defined]
        overlap = user_skills.intersection(job_skills)
        st.write(f"ì‚¬ìš©ì ìŠ¤í‚¬: {', '.join(user_skills) or 'ì—†ìŒ'}")
        st.write(f"ê³µê³  ìŠ¤í‚¬: {', '.join(job_skills) or 'ì—†ìŒ'}")
        st.success(f"ë§¤ì¹­: {', '.join(overlap) or 'ì—†ìŒ'}")


def tab_profile():
    st.header("í”„ë¡œí•„ & ì„¤ì •")
    profile_block()
    st.markdown("---")
    st.caption("ë²¡í„° DB ê²½ë¡œ: {}".format(settings.VECTOR_DB_DIR))
    st.caption("SQLite ê²½ë¡œ: {}".format(settings.SQLITE_PATH))


def main():
    ensure_session()
    if not Path(settings.VECTOR_DB_DIR).exists():
        st.warning("vector_dbê°€ ì—†ìŠµë‹ˆë‹¤. `python -m career_matcher.embedding.vector_pipeline --limit 1000`ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    tabs = st.tabs(["ì¶”ì²œ", "ìŠ¤í‚¬ ë¶„ì„", "í”„ë¡œí•„/ì„¤ì •"])
    with tabs[0]:
        tab_recommend()
    with tabs[1]:
        tab_skills()
    with tabs[2]:
        tab_profile()


if __name__ == "__main__":
    main()
